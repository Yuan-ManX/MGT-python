{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Welcome to the Motion Gestures Toolbox (Python) - Tutorial/Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Video visualisation\n",
    "Videos can be watched as they are, but they can also be used to develop new visualisations to be used for analysis. The aim of creating such alternate displays from video recordings is to uncover features, structures and similarities within the material itself, and in relation to, for example, score material. Three useful visualisation techniques here are motion images, motion history images and motiongrams.\n",
    "\n",
    "MGT can generate both dynamic and static visualizations, as well as some quantitative data:\n",
    "\n",
    "- dynamic visualisations (video files)\n",
    "    - motion video\n",
    "    - motion history video\n",
    "- static visualisations (images)\n",
    "    - motion average image\n",
    "    - motiongrams\n",
    "    - videograms\n",
    "- motion data (csv files)\n",
    "    - quantity of motion\n",
    "    - centroid of motion\n",
    "    - area of motion\n",
    "\n",
    "In the following we will try this ourselves, and look at the different types."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dependencies\n",
    "\n",
    "To make sure you have all the necessary dependencies, evaluate the following line in the terminal:\n",
    "\n",
    "`pip3 install numpy matplotlib opencv-python moviepy ffmpeg ffmpeg-python scipy`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import\n",
    "\n",
    "If you have all the dependencies installed, go ahead and import the `mgmodule`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mgmodule"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The MgObject\n",
    "\n",
    "### Simple video import\n",
    "\n",
    "Now we create our mg (motion gestures) object. You can simply read a video file this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg = mgmodule.MgObject('dance.avi')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "You can watch your video with calling the `show()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg.show() # press q to quit video"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocessing modules\n",
    "### Trimming\n",
    "When creating the object you can also already apply some preprocessing. For example you can trim the duration of the video like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the numbers used for starttime and endtime represent time from the video's timeline in seconds\n",
    "mg = mgmodule.MgObject('dance.avi', starttime=5, endtime=15)\n",
    "mg.show() # view the result, press q to quit video"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "This will create the file *dance_trim.avi* in the same directory."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Skipping\n",
    "In order to save time, skipping every other frame, or more, in the analysis can give you a faster analysis while still getting an idea of the motion. You can for example set this by adding `skip=2`, to skip two frames before including a frame in the analysis, then skipping two again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg = mgmodule.MgObject('dance.avi', starttime=5, endtime=15, skip=2)\n",
    "mg.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "This will create the file *dance_trim_skip.avi* in the same directory. Notice how the added suffixes at the end of the file's name can inform you about the processes the material went through. "
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### It's a chain\n",
    "It is also worth to note that the preprocessing modules work as a chain (- more on that below). In this case that means we first load the video file, then trim its start to 5s and its end to 15s. Then we take the resulting *dance_trim.avi* and discard 2 out of every 3 frames. (Keeping the 1st, skipping 2nd and 3rd, keeping the 4th, skipping 5th and 6th, and so on...) The resulting file of this process is *dance_trim_skip.avi*."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Adjusting contrast and brightness\n",
    "During preprocessing you can also add (or remove) some contrast and brightness of your video.\n",
    "\n",
    "Let's crank up the contrast and brighten up our *dance.avi*!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg = mgmodule.MgObject('dance.avi', starttime=5, endtime=15, skip=3, contrast=100, brightness=20)\n",
    "mg.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Again, the resulting filename *dance_trim_skip_cb.avi* will inform us about the chain of processes *dance.avi* went through."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cropping\n",
    "\n",
    "If the video frame has big areas with no motion occuring, a lot of time could be saved if only the area with motion was used in the analysis. One useful tool developed for the pre-analysis is the crop = 'auto' input, which automatically finds the area with significant motion in the input video. The movement occuring has to be above a low threshold, as to not include irrelevant background motion from shadows, dust etc. Another mode is crop = 'manual', where you can manually mark a rectangle around your area of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Automatic cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg = mgmodule.MgObject('dance.avi', starttime=5, endtime=15, skip=3, contrast=100, brightness=20, crop='auto')\n",
    "mg.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Manual cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg = mgmodule.MgObject('dance.avi', starttime=5, endtime=15, skip=3, contrast=100, brightness=20, crop='manual')\n",
    "mg.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The resulting file is now called *dance_trim_skip_cb_crop.avi*."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Summary of preprocessing modules\n",
    "As we have seen, we can optionally apply four types of preprocessing to the video we load into our MgObject, they are (in order of execution):\n",
    "\n",
    "- trim: Trim contents of the video based on `starttime` and `endtime`.\n",
    "- skip: Skip every n frames, where n is determined by `skip`.\n",
    "- cb: Adjust contrast and brightness of the video, where `contrast` and `brightness` are the level of adjustment in percentages (meaning `contrast=0` will not apply any change). both values range from `-100` to `100`.\n",
    "- crop: Crop frames in video. If `crop='auto'` the module will attempt to find the area of motion, if `crop='manual'` we can draw the cropping rectangle over the first frame.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Keep everything\n",
    "Notice that although we can optionally apply up to four preprocessing modules to our source video, normally we only keep the final result. If you would like to keep the results of all modules, set `keep_all=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg = mgmodule.MgObject('dance.avi', starttime=5, endtime=15, skip=3, contrast=100, brightness=20, crop='auto', keep_all=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "This will output video files:\n",
    "- *dance_trim.avi*\n",
    "- *dance_trim_skip.avi*\n",
    "- *dance_trim_skip_cb.avi*\n",
    "- *dance_trim_skip_cb_crop.avi*"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Processes\n",
    "\n",
    "In the following we will take a look at several functions to further process our videos. These include:\n",
    "- `motion()`: The most frequently used function, generates a *_motion* video, horizontal and vertical motiongrams, and plots about the centroid and quantity of motion found in the video.\n",
    "- `history()`: Generates a *_history* video by layering the last n frames on the current frame for each frame in the video.\n",
    "- `motionhistory()`: Generates a *_motionhistory* video, which is equivalent to calling `history()` on a *_motion* video.\n",
    "- `average()`: Generates an *_average* image of all frames in the video. "
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Motion analysis\n",
    "\n",
    "By calling the `motion()` function, we will generate a number of files from the input video, in the same location as the source file.\n",
    "\n",
    "These include:\n",
    "- *<input_filename>_motion.avi*: The motion video that is used as the source for the rest of the analysis.\n",
    "- *<input_filename>_mgx.png*: A horizontal motiongram.\n",
    "- *<input_filename>_mgy.png*: A vertical motiongram.\n",
    "- *<input_filename>_motion_com_qom.png*: An image file with plots of centroid and quantity of motion\n",
    "\n",
    "We will examine each of these in a little more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mgmodule\n",
    "mg = mgmodule.MgObject('dance.avi', starttime=5, endtime=15, skip=1, contrast=100, brightness=20, crop='auto')\n",
    "mg.motion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls # take a look at the output files"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "We can now look at the results with using the `key` parameter of `show()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg.show(key='motion') # show the motion video of the preprocessed input, in this case 'dance_trim_skip_cb_crop_motion.avi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg.show(key='mgx') # show the horizontal motiongram, here 'dance_trim_skip_cb_crop_mgx.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg.show(key='mgy') # show the vertical motiongram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg.show(key='plot') # show the image of the two plots ('Centroid of motion' and 'Quantity of motion') also shown at the end of motion()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Alternatively we can display the images right here in our notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "x = Image('dance_trim_skip_cb_crop_mgx.png')\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = Image('dance_trim_skip_cb_crop_mgy.png')\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_qom = Image('dance_trim_skip_cb_crop_motion_com_qom.png')\n",
    "com_qom"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Filtering\n",
    "\n",
    "If you think there is too much noise in the output images or video, you may choose to use some other filter settings. \n",
    "\n",
    "Filtertypes availible are: \n",
    "- `Regular` turns all values below thresh to 0.\n",
    "- `Binary` turns all values below thresh to 0, above thres to 1.\n",
    "- `Blob` removes individual pixels with erosion method.\n",
    "\n",
    "\n",
    "Try this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg.motion(filtertype='Blob')\n",
    "mg.show(key='motion')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### History tracking\n",
    "As we have seen above, `motion()` is useful if you want to remove the still content of your video, only keeping what is different in subsequent frames. Sometimes it is also useful to visualize changes between frames in a different way: layering the last n frames on top of the current one as a video delay. With `history()` you can achieve this, optionally setting the `history length` to the number of past frames you want to see on the current frame (ie. the length of the delay).\n",
    "\n",
    "Try this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg.history()\n",
    "mg.show(key='history')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "By default `history_length=10`. Let's increase it to 20!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg.history(history_length=20)\n",
    "mg.show(key='history')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Motion history\n",
    "\n",
    "To expressively visualize the trajectory of a moving content in a video, you can apply the history process on a motion video. You can do this in one step with `motionhistory()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg.motionhistory()\n",
    "mg.show(key='motionhistory')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Average image\n",
    "You can also summarize the content of a video by showing the average of all frames in a single image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg.average()\n",
    "mg.show(key='average')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Embedded in the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "average = Image('dance_trim_skip_cb_crop_average.png')\n",
    "average"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Optical flow\n",
    "It is also possible to track the direction certain points - or all points - move in a video, this is called 'optical flow'. It has two types: the *sparse optical flow*, which is for tracking a small (sparse) set of points, visualized with an overlay of dots and lines drawing the trajectory of the chosen points as they move in the video.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg.flow.sparse()\n",
    "mg.show(key='sparse')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Note that sparse optical flow usually works well with slow and continuous movements, where the points to be tracked are not occluded by other objects throughout the course of motion.\n",
    "Where spare optical flow becomes less reliable, *dense optical flow* often yields more robust results. In dense optical flow the analysis attempts to track the movement of each pixel (or more precisely groups of pixels), colorcoding them with a unique color for each unique direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg.flow.dense()\n",
    "mg.show(key='dense')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sparse optical flow can get confused by too fast movement (ie. too big distance between the locations of a tracked point between two consequtive frames), so it is typically advised not to have a too high `skip` value in the preprocessing stage for it to work properly.\n",
    "Dense optical flow on the other hand has issues with very slow movement, which sometimes gets below the treshold of what is considered 'a movement' resulting in a blinking video, where the more-or-less idle moments are rendered completely black. If your source video contains such moments, you can try setting `skip_empty=True`, which will discard all the (completely) black frames, eliminating the binking. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg.flow.dense(skip_empty=True)\n",
    "mg.show(key='dense')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Chaining\n",
    "\n",
    "So far our workflow consisted of the following steps:\n",
    "- 1. Creating an MgObject which loads a video file and optionally applies some preprocessing to it.\n",
    "- 2. Calling a process on the MgObject.\n",
    "- 3. Viewing the result.\n",
    "\n",
    "Something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg = mgmodule.MgObject('dance.avi', starttime=5, endtime=15, skip=3)\n",
    "mg.motion()\n",
    "mg.show(key='motion')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "This is convenient if you want to apply several different processes on the same input video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg = mgmodule.MgObject('dance.avi', starttime=5, endtime=15, skip=3)\n",
    "mg.motion()\n",
    "mg.history()\n",
    "mg.motionhistory()\n",
    "mg.average()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The Motion Gestures Toolbox also offers an alternative workflow in case you want to apply a proccess on the result of a previous process. Although `show()` is not really a process (ie. it does not yield a file as a result) it can provide a good example of the use of chaining:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this...\n",
    "mg.motion().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...is the equivalent of this!\n",
    "mg.motion()\n",
    "mg.show(key='motion')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "It also works with images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg.average().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "But chaining can go further than this. How about reading (and preprocessing) a video, rendering its motion video, the motion history and the average of the motion history, with showing the *_motion_history_average.png* at the end - all as a one-liner?!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgmodule.MgObject('dance.avi', skip=4, crop='auto').motion().history().average().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# equivalent without chaining\n",
    "mg = mgmodule.MgObject('dance.avi', skip=4, crop='auto')\n",
    "mg.motionhistory()\n",
    "mh = mgmodule.MgObject('dance_skip_crop_motionhistory.avi')\n",
    "mh.average()\n",
    "mh.show(key='average')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Some other examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rendering and viewing the motion video \n",
    "mgmodule.MgObject('dance.avi', skip=4).motion().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rendering the motion video, the motion history video, and viewing the latter\n",
    "mgmodule.MgObject('dance.avi', skip=3).motion().history().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rendering the motion video, the motion average image, and viewing the latter\n",
    "mgmodule.MgObject('dance.avi', skip=15).motion().average().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Chaining can also save time (and space) when designing loops for processing a folder of videos. Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from mgmodule import MgObject as Mg\n",
    "\n",
    "my_videos_folder = 'C:/Users/User/Desktop/test-videos/'\n",
    "\n",
    "my_videos = [my_videos_folder + video for video in os.listdir(my_videos_folder) if os.path.splitext(video)[1] in ['.avi', '.mp4', '.mov', '.mkv']]\n",
    "\n",
    "for video in my_videos:\n",
    "    print(f'Processing {video}...')\n",
    "    Mg(video, skip=10).motion().history().average()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}